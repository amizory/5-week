# Основы виртуализации и контейнеризации

* [Основы Docker](#Основы-Docker)
* [Основны Containers orchestration](#Основны-Containers-orchestration )
* [Основы Kubernetes](#Основы-Kubernetes)
* [kubectl](#kubectl)

## <a id="Основы-Docker">Основы Docker</a>

```txt
1 - Компоненты Docker.
2 - Установка и настройка Docker на Linux, Windows и Mac.
3 - Понятие образа и контейнера.
4 - Синтаксис Dockerfile.
5 - Docker Registry, публичные и приватные Registry. 
6 - Docker-compose.
7 - Использование Docker в CI/CD пайплайнах.
8 - Dockerfile Best Practice.
```

### Notice-1

```txt
1 - Из каких компонентов состоит docker?

->  Docker - ПО для автоматизации управления контейнерами
    (пакеты = образы / репозиторий = registry)
    - стандартизирует упаковку app
    - зависимости 
    - воспроизводимость
    - min overhead (ресурсы)

    1 - Docker Daemon
    - серверная часть
    - на хост машине
    - скачивает образы из registry и запускает из них контейнеры
    - создает сеть между контейнерами
    - собирает логи контейнера
    - создание нового образа

    2 - Docker CLI
    - консольная утилита для работы с докер-демоном
    - может работать не только локально, но и по сети

    3 - Image
    - упаковка контейнера
    - из них запускаются контейнеры 
    - хранятся в докер registry
    - имя, hash, tag - версионирование
    - слоеная структура
    - создаются (build) по инструкциям (Dockerfile)

    4 - Registry
    - хранит образы докера
    - реестр - docker hub
    - можно сделать свой

    5 - Dockerfile
    - инструменты для создания образа
    - слоеная система

    6 - Container
    - запускается из образа
    - изолирован
    - должен содержать в себе все для работы приложения
    - 1 процесс - 1 контейнер
```

```txt
2 - Что такое образ? 

->  Образ (Image) - шаблон для контейнера, содержит приложение, его зависимости,
    конфигурацию и окружение. Это базовый файл, из которого можно создать контейнер.
    Образ включает в себя:
    - Коды приложения
    - Зависимости (библиотеки, зависимости)
    - Конфигурацию (параметры, настройки)
    - Операционную систему
    - Установленные пакеты и инструменты
    Образ можно сравнить с шаблоном для дома, в котором все необходимое уже
    есть, а контейнер - это готовый дом, созданный на основе этого шаблона. Из
    образа можно создать сколько угодно контейнеров, каждый из которых будет иметь
    отдельную идентичность и работать независимо.
```

```txt
3 - Что такое контейнер?

->  Контейнер (Container) - инстанс образа, который содержит приложение и
    его окружение. Это отдельная экземпляр приложения, работающий в изоляции
    от других контейнеров и хостовой системы.
    Контейнер имеет следующие характеристики:
    - Собственная файловая система
    - Собственный процессор и память
    - Изолированный доступ к ресурсам хостовой системы
    - Управляемый ресурсами (CPU, память, сетью и т.п.)
    - Могут быть созданы, остановлены, удалены и перезапущены

    Контейнеры позволяют развертывать приложения в изоляции, что обеспечивает
    следующие преимущества:
    - Улучшение безопасности
    - Упрощение развертывания и масштабирования приложений
    - Уменьшение зависимости от окружения
    - Улучшение производительности и надежности.
```

```txt
4 - Что такое Docker Registry?

->  Docker Registry - центральный репозиторий, где хранятся образы Docker.
    Это сервер, который позволяет хранить, скачивать и распространять образы Docker.
    Docker Registry может быть:
    - Публичным репозиторием, доступным для всех пользователей (например, Docker Hub)
    - Приватным репозиторием, доступным только для определенных пользователей или организаций
    - Локальным репозиторием, хранящим образы на локальной машине или в локальной сети
    Docker Registry позволяет:
    Загружать и хранить образы Docker
    - Скачивать и использовать образы Docker в других контейнерах
    - Управлять доступом к образам и репозиториям
    - Улучшать безопасность и контроль над образами и контейнерами.
```

```txt
5 - Как скачать образ с приватного Docker Registry, требующего логин/пароль или токен?

->  Чтобы скачать образ из приватного Docker Registry, требующего логин/пароль
    или токен, вы можете использовать команду docker login для аутентификации,
    а затем скачать образ с помощью команды docker pull. Вот примеры:
    -----------------------------------------------------------------
    docker login myregistry.example.com
    Вам будет предложено ввести логин и пароль. После успешной
    аутентификации Docker сохранит ваши учетные данные в файле ~/.docker/config.json
    docker pull myregistry.example.com/myimage:latest
    -----------------------------------------------------------------
    Получите токен доступа к вашему приватному Docker Registry. Это может
    быть сделано с помощью команды docker login с ключом --username и --password
    docker login myregistry.example.com --username=myuser --password=mypassword
    echo "mypassword" | docker login myregistry.example.com --username=myuser --password-stdin
    Вам будет выдан токен доступа, который можно использовать для аутентификации.
    docker pull myregistry.example.com/myimage:latest --auth mytoken
    -----------------------------------------------------------------
    Вы также можете сохранить ваши учетные данные в файле конфигурации ~/.docker/config.json
    и использовать его для аутентификации. Файл конфигурации должен иметь следующий формат:
    {
    "auths": {
        "myregistry.example.com": {
        "auth": "dXNlcjpwYXNzd29yZA=="
        }
      }
    }
    После сохранения файла конфигурации вы можете скачать образ из вашего приватного
    Docker Registry без необходимости ввода логина и пароля
    docker pull myregistry.example.com/myimage:latest
```

```txt
6 - Что такое Docker-compose?

->  Docker-compose - это инструмент для определения и запуска многоконтейнерных
    Docker-приложений. С его помощью можно описать все контейнеры, необходимые для
    работы приложения, и их взаимодействие друг с другом.
    Docker-compose позволяет:
    - Определить все контейнеры, необходимые для работы приложения, в едином
    файле конфигурации (docker-compose.yml).
    - Запустить все контейнеры одновременно с помощью одной команды (docker-compose up).
    - Управлять контейнерами, включая запуск, остановку, перезапуск и удаление.
    - Создать сеть для контейнеров, чтобы они могли общаться друг с другом.
    - Определить зависимости между контейнерами, чтобы они запускались в правильном порядке.
    Файл конфигурации docker-compose.yml содержит описание всех контейнеров, включая:
    - Образ, из которого создается контейнер
    - Порты, которые контейнер слушает
    - Том, который монтируется в контейнер
    - Переменные окружения, которые устанавливаются в контейнере
    - Зависимости между контейнерами
```

```txt
7 - Как запустить Docker контейнер?

->  docker run 
    -d          ---> background mode
    --name      ---> define name
    --rm        ---> remove container after exits
    -p          ---> port mapping
    -P          ---> random port
    -e          ---> env
    -v          ---> 1. volume PATH(HOST):PATH(Docker container)
                ---> 2. anonymous volume PATH(Docker container)
                ---> 3. named volume NAME:PATH(Docker container)
                           cd /var/lib/docker/volumes
    --net       ---> network name
    --ip        ---> unreal ip

    docker start <CONTAINER_ID>
```

```txt
8 - Как выполнить команду внутри Docker контейнера?

->  docker exec -it testapp /bin/bash
    -i - включить интерактивный режим, позволяющий вводить команды в контейнере.
    -t - включить псевдо-терминал, позволяющий выводить результаты команды в терминале.
    -u - указать пользователя, под которым будет выполнена команда.
    -w - указать рабочий каталог, в котором будет выполнена команда.
    docker exec -u root mycontainer ps aux
    docker exec -w /var/log mycontainer bash -c "cd /var/log && ls -l"
    docker attach mycontainer
```

```txt
9 - Как посмотреть логи Docker контейнера?

->  Чтобы посмотреть логи Docker контейнера, можно использовать команду
    docker logs. Эта команда позволяет просматривать журналы контейнера, которые
    содержат информацию о его работе.
    -f - включить режим "follow", который позволяет просматривать логи в режиме реального времени.
    -n - указать количество строк логов, которые нужно вывести.
    -t - включить вывод меток времени для каждой строки лога.
    --since - указать время, с которого нужно выводить логи.
    --until - указать время, до которого нужно выводить логи.

    Другие 
    docker inspect <NAME>
    docker stats <NAME>
    docker port <NAME>
```

### Intern-1

```txt
1 - Что такое слои в Docker?

->  Слои в Docker - это концепция, которая позволяет создавать образы контейнеров
    из набора слоев, каждый из которых представляет собой набор изменений, внесенных в образ.

    Каждый слой представляет собой набор файлов и директорий, которые добавляются или
    изменяются в образе. Слои можно рассматривать как набор "патчей", которые накладываются
    друг на друга, чтобы создать окончательный образ контейнера.

    Слои в Docker имеют следующие свойства:
    - Независимость: каждый слой независим от других слоев и может быть создан,
    изменен или удален без влияния на другие слои.
    - Накопление: слои накладываются друг на друга, чтобы создать окончательный
    образ контейнера.
    - Повторное использование: слои можно повторно использовать в разных образах
    контейнеров, что позволяет   уменьшить размер образов и увеличить скорость
    создания контейнеров.

    Слои в Docker используются для следующих целей:
    - Создание образов: слои используются для создания образов контейнеров из
    набора изменений, внесенных в базовый образ.
    - Обновление образов: слои используются для обновления образов контейнеров,
    добавляя новые слои или изменяя существующие.
    - Создание контейнеров: слои используются для создания контейнеров из образов,
    накладывая слои друг на друга.

    Пример слоев в Docker:
    - Базовый слой: Ubuntu 18.04
    - Слой 1: добавление пакета Apache
    - Слой 2: добавление пакета MySQL
    - Слой 3: добавление конфигурации Apache
```

```txt
2 - Чем директива ADD отличается от COPY?

->  Директивы ADD и COPY в Dockerfile используются для копирования файлов
    из текущей директории в образ контейнера

    COPY:
    - Копирует файлы из текущей директории в образ контейнера.
    - Не может копировать файлы из удаленных источников.
    - Не может распаковывать архивы.
    - Простая и безопасная директива.
    COPY index.html /var/www/html/

    ADD:
    - Копирует файлы из текущей директории в образ контейнера.
    - Может копировать файлы из удаленных источников (например, URL-адресов).
    - Может распаковывать архивы (например, tar, zip).
    - Более сложная и мощная директива, но также более опасная, поскольку может
    копировать файлы из удаленных источников.
    ADD https://example.com/index.html /var/www/html/
    ADD myapp.tar.gz /var/www/html/
```

```txt
3 - Чем директива ARG отличается от ENV?

->  Директивы ARG и ENV в Dockerfile используются для определения переменных
    окружения в образе контейнера.
    
    ARG:
    - Определяет переменную окружения только для процесса сборки образа.
    - Не сохраняется в образе контейнера после завершения процесса сборки.
    - Может быть использована для передачи значений переменных окружения из
    файла docker-compose.yml или командной строки docker build.
    ARG MY_VAR=defaultValue

    ENV:
    - Определяет переменную окружения, которая сохраняется в образе контейнера.
    - Доступна в процессе сборки образа и в запущенном контейнере.
    ENV MY_VAR=defaultValue

    Основное различие между ARG и ENV заключается в том, что ARG определяет
    переменную окружения только для процесса сборки образа, в то время как ENV
    определяет переменную окружения, которая сохраняется в образе контейнера и
    доступна в процессе сборки и в запущенном контейнере.

    # Dockerfile
    ARG MY_VAR=defaultValue
    ENV MY_VAR=$MY_VAR

    docker build -t myimage --build-arg MY_VAR=newValue .
```

```txt
4 - Чем директива CMD отличается от ENTRYPOINT? Могут ли они использоваться вместе?


->  Директивы CMD и ENTRYPOINT в Dockerfile используются для определения команды,
    которая будет выполнена при запуске контейнера

    CMD:
    - Определяет команду, которая будет выполнена при запуске контейнера, если не
    указана другая команда.
    - Может быть переопределена при запуске контейнера с помощью команды docker run.
    CMD ["echo", "Hello, World"]

    ENTRYPOINT:
    - Определяет команду, которая будет выполнена при запуске контейнера, и не может
    быть переопределена при запуске контейнера.
    - Используется для определения основной команды, которая будет выполнена при
    запуске контейнера.
    ENTRYPOINT ["echo", "Hello, World"]

    Да, директивы CMD и ENTRYPOINT могут использоваться вместе. В этом случае
    ENTRYPOINT будет определять основную команду, которая будет выполнена при
    запуске контейнера, а CMD будет определять аргументы, которые будут переданы
    этой команде.
    ENTRYPOINT ["echo"]
    CMD ["Hello, World"]

    Когда использовать CMD и ENTRYPOINT вместе?
    - Когда вы хотите определить основную команду, которая будет выполнена при запуске
    контейнера, и аргументы, которые будут переданы этой команде.
    - Когда вы хотите обеспечить гибкость в определении команды, которая будет выполнена
    при запуске контейнера, но также хотите определить основную команду, которая будет
    выполнена по умолчанию.
    В общем, если вы хотите определить команду, которая будет выполнена при запуске
    контейнера, и аргументы, которые будут переданы этой команде, используйте директивы
    CMD и ENTRYPOINT вместе. Если вы хотите определить основную команду, которая будет
    выполнена при запуске контейнера, и не хотите, чтобы она могла быть переопределена,
    используйте директиву ENTRYPOINT.
```

```txt
5 - Можно ли (и если да, то как) переопределить директивы CMD и ENTRYPOINT из Dockerfile
    при запуске контейнера? 

->  Да, можно переопределить директивы CMD и ENTRYPOINT
    из Dockerfile при запуске контейнера.
    
    Директива CMD можно переопределить при запуске контейнера с помощью
    команды docker run и аргумента -c.
    docker run -c "echo Hello, World" myimage

    Директива ENTRYPOINT можно переопределить при запуске контейнера с
    помощью команды docker run и аргумента --entrypoint.
    docker run --entrypoint echo myimage Hello, World

    docker run -c "echo Hello, World" --entrypoint echo myimage
```

```txt
6 - Как подключить volume к контейнеру? Какие типы volume`ов поддерживает Docker?

->  Docker поддерживает следующие типы volume:

    -v          ---> 1. volume PATH(HOST):PATH(Docker container)
                ---> 2. anonymous volume PATH(Docker container)
                        /var/lib/docker/volumes/_data
                ---> 3. named volume NAME:PATH(Docker container)
                        cd /var/lib/docker/volumes/<имя_тома>

    - Bind mount: монтирует директорию на хосте в директорию в
    контейнере.
        - монтирование
        - доступ через контейнер
        docker run -v /host/path:/container/path myimage

    - Volume: создает новый volume, который может быть использован
    несколькими контейнерами.
        - доступ через контейнер
        - один том на несколько контейнеров
        docker volume create myvolume
        docker run -v myvolume:/container/path myimage

    - tmpfs: создает временный volume, который будет удален после
    завершения работы контейнера.
        - в озу
        - максимальная скорость-запись
        docker run -v /container/path:tmpfs myimage

    Volume 
    - Просто шарит данные между контейнерами
    - У хоста нет нужной структуры каталогов
    - Данные лучше хранить не локально

    Bind mount
    - Пробросить конфигурацию с хоста в контейнер
    - Расшарить исходники и/или уже собранные приложения 
    - Есть стабильная система структуры каталогов и файлов, которые нужно расшарить между
    контейнерами
```

### Advanced-1

```txt
1 - Какие типы сокетов поддерживает docker cli?

->  В контексте Docker, сокет (socket) - это интерфейс, который позволяет
    процессам на одной и той же машине или на разных машинах общаться друг с другом.

    В Docker, сокет используется для связи между Docker демоном (dockerd) и
    Docker CLI (docker). Docker демон - это процесс, который управляет контейнерами и
    образами, а Docker CLI - это инструмент, который позволяет пользователям взаимодействовать
    с Docker демоном.

    Сокет в Docker используется для следующих целей:
    - Управление контейнерами: Docker демон использует сокет для управления контейнерами,
    таких как запуск, остановка, удаление и т. д.
    - Обмен данными: Docker демон и Docker CLI используют сокет для обмена данными, такими
    как образы, контейнеры, логами и т. д.
    - Аутентификация: Docker демон использует сокет для аутентификации пользователей и
    проверки прав доступа.

    - UNIX сокеты: Docker CLI может использовать UNIX сокеты для связи с
    Docker демоном. UNIX сокеты являются локальными сокетами, которые позволяют
    процессам на одной и той же машине общаться друг с другом.
    docker -H unix:///var/run/docker.sock ps

    - TCP сокеты: Docker CLI может использовать TCP сокеты для связи с Docker
    демоном по сети. TCP сокеты являются протоколом, который позволяет процессам
    на разных машинах общаться друг с другом по сети.
    docker -H tcp://localhost:2375 ps

    - TLS сокеты: Docker CLI может использовать TLS сокеты для безопасной связи с Docker
    демоном по сети. TLS сокеты являются протоколом, который обеспечивает безопасную
    передачу данных по сети.

    Чтобы использовать TLS сокеты с Docker CLI, необходимо указать адрес и порт
    сокета, а также сертификат и ключ в командной строке. Например:
    docker -H tls://localhost:2376 --tlscacert=/path/to/ca.crt 
    --tlscert=/path/to/client.crt --tlskey=/path/to/client.key ps

    Docker CLI может использовать сокет по умолчанию, если он не указан
    в командной строке. Сокет по умолчанию зависит от операционной системы
    и может быть изменен с помощью переменной окружения DOCKER_HOST.

    Например, на Linux сокет по умолчанию является UNIX сокетом /var/run/docker.sock,
    а на Windows сокет по умолчанию является TCP сокетом localhost:2375.
```

```txt
2 - Какие Best Practice надо следовать при написание Dockerfile? 

->  - Используйте конкретные образы: Используйте конкретные образы, а не общий образ
    latest. Это позволит вам контролировать версию образа и избежать проблем с совместимостью.
    - Упаковывайте зависимости: Упаковывайте зависимости в образ, а не устанавливайте
    их во время запуска контейнера. Это позволит вам контролировать версию зависимостей
    и избежать проблем с совместимостью.
        RUN pip install -r requirements.txt
    - Используйте команду COPY: Используйте команду COPY для копирования файлов в образ,
    а не команду ADD. Команда COPY более безопасна и позволяет избежать проблем с
    правами доступа.
    - Используйте команду RUN: Используйте команду RUN для выполнения команд в
    образе, а не команду CMD. Команда RUN более безопасна и позволяет избежать
    проблем с правами доступа.
    - Упрощайте команды: Упрощайте команды в Dockerfile, используя команды && и ||.
    Это позволит вам избежать проблем с правами доступа и упростить процесс сборки образа.
    - Используйте переменные: Используйте переменные в Dockerfile для хранения значений,
    которые могут изменяться. Это позволит вам избежать проблем с правами доступа и
    упростить процесс сборки образа.
    - Используйте директиву WORKDIR: Используйте директиву WORKDIR для установки
    рабочей директории в образе. Это позволит вам избежать проблем с правами доступа
    и упростить процесс сборки образа.
    - Используйте директиву EXPOSE: Используйте директиву EXPOSE для указания портов,
    которые должны быть открыты в образе. Это позволит вам избежать проблем с правами
    доступа и упростить процесс сборки образа.
    - Используйте директиву CMD: Используйте директиву CMD для указания команды, которая
    должна быть выполнена при запуске контейнера. Это позволит вам избежать проблем с
    правами доступа и упростить процесс сборки образа.
    - Тестируйте образ: Тестируйте образ после сборки, чтобы убедиться, что он работает
    корректно. Это позволит вам избежать проблем с правами доступа и упростить процесс
    сборки образа.
```

```txt
3 - Что делает команда docker commit?

->  Команда docker commit используется для создания нового образа Docker
    из существующего контейнера.

    Когда вы запускаете команду docker commit, Docker создает новый образ, который
    представляет собой снимок текущего состояния контейнера. Этот новый образ
    включает в себя все изменения, которые были внесены в контейнер с момента его создания.

    docker commit -m "newimage" mycontainer myimage:latest
```

```txt
4 - Что такое Copy on Write?

->  Copy on Write (CoW) - это механизм, который позволяет создавать новые
    образы Docker из существующих образов, не копируя все данные из исходного образа.
    Когда вы создаете новый образ Docker с помощью команды docker commit, Docker использует
    механизм CoW для создания нового образа. Этот механизм работает следующим образом:

    - Docker создает новый образ, который является копией исходного образа.
    - Docker создает новый слой, который содержит все изменения, внесенные в новый образ.
    - Docker сохраняет ссылку на исходный образ, чтобы избежать копирования всех данных
    из исходного образа.

    Благодаря механизму CoW, Docker может создавать новые образы быстро и эффективно, не
    копируя все данные из исходного образа. Это позволяет уменьшить размер образов и
    увеличить скорость создания новых образов

    Теперь мы хотим создать новый образ myimage:latest, который будет содержать
    все файлы и директории из исходного образа ubuntu:latest, а также добавленный
    файл hello.txt в директорию /app.


    - Когда мы создаем новый образ myimage:latest, Docker использует механизм CoW
    для создания нового образа. Этот механизм работает следующим образом:
    - Docker создает новый образ, который является копией исходного образа ubuntu:latest.
    - Docker создает новый слой, который содержит все изменения, внесенные в новый образ.
    Новый слой, который был создан Docker, содержит только добавленный файл hello.txt
    в директорию /app. Этот слой является копией исходного образа ubuntu:latest, но с
    добавленным файлом hello.txt.
    - Docker сохраняет ссылку на исходный образ ubuntu:latest, чтобы избежать копирования
    всех данных из исходного образа. Это означает, что новый образ myimage:latest будет
    использовать данные из исходного образа ubuntu:latest, но с добавленным файлом hello.txt
```

## <a id="Основны-Containers-orchestration ">Основны Containers orchestration</a>

```txt
1 - Понятие Containers orchestration.
2 - Kubernetes, что это такое, зачем и где используется.
3 - Понятие кластера.
```

### Notice-2

```txt
1 - Что такое Containers orchestration? 

->  Контейнерная оркестрация (Containers orchestration) - это автоматизация управления
    контейнерами, включая их запуск, масштабирование, мониторинг и управление зависимостями
    между ними. Это позволяет эффективно управлять большим количеством контейнеров, которые
    могут работать на разных хостах, и обеспечивает высокую доступность и масштабируемость
    приложений.

    Например, если у вас есть веб-приложение, которое состоит из нескольких микросервисов,
    таких как база данных, сервер приложений и сервер фронтэнда, контейнерная оркестрация
    может автоматически запускать и масштабировать контейнеры для каждого микросервиса, а
    также управлять взаимодействием между ними.
    - Некоторые примеры контейнерной оркестрации включают:
    - Автоматическое развертывание контейнеров на разных хостах
    - Масштабирование контейнеров в зависимости от нагрузки
    - Мониторинг состояния контейнеров и автоматическое восстановление в случае сбоя
    - Управление сетевыми соединениями между контейнерами
    - Обеспечение безопасности и аутентификации контейнеров
```

```txt
2 - Какие есть примеры данного класса ПО?

->  - Kubernetes: один из наиболее популярных инструментов контейнерной оркестрации,
    который позволяет автоматически развертывать, масштабировать и управлять контейнерами.
    - Docker Swarm/Apache Mesos: инструмент контейнерной оркестрации, который
    позволяет автоматически развертывать и масштабировать контейнеры в кластере.
    - Red Hat OpenShift: платформа контейнерной оркестрации, которая позволяет автоматически
    развертывать, масштабировать и управлять контейнерами.
    - Rancher/Nomad: инструмент контейнерной оркестрации, который позволяет автоматически
    развертывать, масштабировать и управлять контейнерами.
    - Google Kubernetes Engine (GKE): сервис контейнерной оркестрации, который позволяет
    автоматически развертывать, масштабировать и управлять контейнерами в облаке Google Cloud.
    - Amazon Elastic Container Service (ECS): сервис контейнерной оркестрации, который
    позволяет автоматически развертывать, масштабировать и управлять контейнерами в облаке
    Amazon Web Services.
```

```txt
3 - Что такое кластер (в общем смысле)?

->  Кластер (англ. cluster) - это группа компьютеров или узлов, которые работают вместе
    как единая система, чтобы обеспечить высокую доступность, масштабируемость и
    производительность.

    В общем смысле, кластер - это совокупность нескольких машин, которые объединены
    вместе для достижения общей цели. Кластеры могут быть использованы для различных
    целей, таких как:
    - Обработка больших данных
    - Выполнение сложных вычислений
    - Обеспечение высокой доступности и отказоустойчивости
    - Масштабирование приложений
    - Обеспечение безопасности и защиты данных

    Кластеры могут состоять из нескольких машин, которые могут быть физическими или
    виртуальными, и которые могут быть расположены в одном месте или распределены по
    нескольким местам.

    В контексте контейнерной оркестрации, кластер - это группа машин, на которых запускаются
    контейнеры, и которые управляются оркестратором для обеспечения высокой доступности и
    масштабируемости приложений.
```

### Intern-2/Advanced-2

```txt
1 - Какие есть альтернативы Kubernetes?

->  - Kubernetes является одним из наиболее популярных инструментов контейнерной оркестрации,
    но существуют альтернативы, которые могут быть более подходящими для определенных случаев
    использования. Вот альтернативы Kubernetes:

    - Docker Swarm: Docker Swarm - это инструмент контейнерной оркестрации, который позволяет
    автоматически развертывать и масштабировать контейнеры в кластере. Docker Swarm является
    частью платформы Docker и предоставляет простой и легкий способ управления контейнерами.

    - Apache Mesos: Apache Mesos - это инструмент контейнерной оркестрации, который позволяет
    автоматически развертывать и масштабировать контейнеры в кластере. Mesos является более
    старым инструментом, чем Kubernetes, но он все еще широко используется в промышленности.

    - Nomad: Nomad - это инструмент контейнерной оркестрации, который позволяет автоматически
    развертывать и масштабировать контейнеры в кластере. Nomad является более легким и
    простым инструментом, чем Kubernetes, но он все же предоставляет мощные возможности
    управления контейнерами.

    - Rancher: Rancher - это платформа контейнерной оркестрации, которая позволяет
    автоматически развертывать и масштабировать контейнеры в кластере. Rancher предоставляет
    простой и легкий способ управления контейнерами, а также поддерживает несколько
    оркестраторов, включая Kubernetes и Docker Swarm.

    - OpenShift: OpenShift - это платформа контейнерной оркестрации, которая позволяет
    автоматически развертывать и масштабировать контейнеры в кластере. OpenShift
    предоставляет простой и легкий способ управления контейнерами, а также поддерживает
    несколько оркестраторов, включая Kubernetes.

    - Amazon ECS: Amazon ECS - это сервис контейнерной оркестрации, который позволяет
    автоматически развертывать и масштабировать контейнеры в кластере. Amazon ECS является
    частью платформы Amazon Web Services и предоставляет простой и легкий способ управления
    контейнерами.

    - Google Cloud Run: Google Cloud Run - это сервис контейнерной оркестрации, который
    позволяет автоматически развертывать и масштабировать контейнеры в кластере. Google
    Cloud Run является частью платформы Google Cloud и предоставляет простой и легкий
    способ управления контейнерами.
```

## <a id="Основы-Kubernetes">Основы Kubernetes</a>

```txt
1 - Компоненты Kubernetes.
2 - Абстракции Kubernetes.
```

### Notice-3

```txt
1 - Какие компоненты Kubernetes находятся на master-нодах?

->  api-server -> внешний сервер, который обрабатывает запросы api;
    control-manager -> ответственный за развертывание;
    etcd -> база данных, в которой хранится вся информация о кластере, узлах и статусе;
    планировщик -> место, где будут запущены модули (планирование);
    cloud-controller -> взаимодействие с облаком (балансировщик нагрузки, дисковые тома);
```

```txt
2 - Какие компоненты Kubernetes находятся на worker-нодах?

->  kubelet -> мониторинг выполнения задачи на узле;
    proxy -> сетевое подключение и балансировщик нагрузки;
    cadvisior -> планировщик получения информации о состоянии кластера и запущенных процессах;
    pod -> контейнер или контейнеры;

    Approval Cycle

    container -> приложение;
    pod -> объект (модуль);
    scheduler -> планирование нового модуля;
    replicaset -> модуль управления (изменить)
    deploy -> управление репликами, exe pid-env;
    service -> веб-прокси/балансировщик нагрузки;
    etcd -> вся информация (кластер/развертывание/ресурсы/журналы)
```

```txt
3 - Что такое Pod/ReplicaSet/Deployment/Service/Secret/ConfigMap?

->  - Pod: наименьшая единица развертывания в Kubernetes, представляет собой один или
    несколько контейнеров, работающих вместе.
    - ReplicaSet: обеспечивает запуск и управление несколькими копиями подов (репликами)
    для обеспечения высокодоступности и масштабируемости.
    - Deployment: управляет развертыванием подов и обеспечивает обновление версий приложения.
    - Service: обеспечивает доступ к подам через постоянный IP-адрес и DNS-имя, независимо от
    того, где находятся поды в кластере.
    - Secret: хранит конфиденциальную информацию, такую как пароли, ключи и сертификаты, и
    обеспечивает безопасный доступ к ней.
    - ConfigMap: хранит конфигурационные данные, такие как параметры приложения, и
    обеспечивает доступ к ним.

    ReplicaSet:
    Основная цель: обеспечить определенное количество идентичных подов (реплик) в кластере.
    - ReplicaSet управляет только подами, которые были созданы им самим.
    - ReplicaSet не может обновлять поды, он только создает новые или удаляет существующие.
    - ReplicaSet не может масштабировать поды автоматически.

    Deployment:
    Основная цель: обеспечить управление жизненным циклом приложения, включая создание,
    обновление и масштабирование подов.
    - Deployment управляет ReplicaSet, который создает и управляет подами.
    - Deployment может обновлять поды, создавая новые версии ReplicaSet.
    - Deployment может масштабировать поды автоматически.
```

### Intern-3

```txt
1 - Какие типы сервисов есть в kubernetes?

->  - ClusterIP: Этот тип сервиса предоставляет доступ к подам внутри кластера. Сервис
    получает IP-адрес из диапазона кластера и становится доступен только изнутри кластера.
    - NodePort: Этот тип сервиса предоставляет доступ к подам извне кластера через
    определенный порт на каждом узле кластера. Сервис получает IP-адрес из диапазона
    кластера и становится доступен извне кластера через порт, указанный в определении сервиса.
    - LoadBalancer: Этот тип сервиса предоставляет доступ к подам извне кластера через
    балансировщик нагрузки. Сервис получает IP-адрес из диапазона кластера и становится
    доступен извне кластера через балансировщик нагрузки.
    - ExternalName: Этот тип сервиса позволяет указать внешний сервис, который не находится
    в кластере. Сервис не получает IP-адрес из диапазона кластера и не становится доступен
    изнутри кластера.
```

```txt
2 - Что такое DaemonSet/StatefulSet?

->  DaemonSet - это тип ресурса в Kubernetes, который позволяет запускать
    определенное количество подов на каждом узле кластера. DaemonSet гарантирует,
    что на каждом узле кластера будет запущен определенный под, даже если узел
    перезагрузится или будет удален.

    DaemonSet используется для следующих целей:
    - Мониторинг узлов кластера
    - Сбор логов и метрик
    - Обновление конфигурации узлов
    - Запуск агентов безопасности
    DaemonSet имеет следующие характеристики:
    - DaemonSet создает поды на каждом узле кластера
    - DaemonSet гарантирует, что на каждом узле кластера будет запущен определенный под
    - DaemonSet может быть использован для запуска подов с высоким приоритетом

    StatefulSet - это тип ресурса в Kubernetes, который позволяет запускать
    определенное количество подов с сохранением состояния. StatefulSet гарантирует,
    что каждый под будет иметь уникальное имя и будет сохранять свое состояние даже
    после перезапуска.

    StatefulSet используется для следующих целей:
    - Запуск баз данных
    - Запуск сообщественных систем
    - Запуск систем хранения данных
    StatefulSet имеет следующие характеристики:
    - StatefulSet создает поды с уникальными именами
    - StatefulSet гарантирует, что каждый под будет сохранять свое состояние
    - StatefulSet может быть использован для запуска подов с высоким приоритетом
```

```txt
3 - Что такое Persistent Volume?

->  Persistent Volume (PV) - это ресурс в Kubernetes, который представляет собой
    постоянное хранилище данных. PV позволяет сохранять данные даже после того, как
    под, который использовал эти данные, был удален или перезапущен.

    PV может быть создан из различных источников, таких как:
    - Локальный диск
    - Сеть хранения данных (SAN)
    - Облачное хранилище (например, Amazon S3)
    - Distributed File System (DFS)
    - HostPath (директория на хост-машине)

    PV имеет следующие характеристики:
    - PV представляет собой постоянное хранилище данных
    - PV может быть использован для сохранения данных приложения
    - PV может быть использован для обеспечения доступа к данным из нескольких подов
    - PV может быть использован для обеспечения доступа к данным из разных namespace

    PV может быть доступен через различные интерфейсы, такие как:
    - NFS (Network File System)
    - Ceph
    - GlusterFS
    - iSCSI

    - ReadWriteOnce (RWO): Этот режим позволяет только одному поду читать и записывать данные
    в PV. Если несколько подов пытаются использовать PV в этом режиме, они получат ошибку.
    - ReadOnlyMany (ROX): Этот режим позволяет нескольким подам читать данные из PV, но никто
    не может записывать данные в PV.
    - ReadWriteMany (RWX): Этот режим позволяет нескольким подам читать и записывать
    данные в PV.
    - ReadWriteOncePod (RWOP) том может быть смонтирован как чтение-запись одним Pod.
    Используйте режим доступа ReadWriteOncePod, если вы хотите гарантировать, что только
    один pod во всем кластере может читать этот PVC или записывать в него.

    Эти accessModes определяют, как поды могут использовать PV, и помогают обеспечить
    безопасность и целостность данных.
    - Например, если вы хотите использовать PV для хранения конфигурационных файлов,
    вы можете использовать режим ReadOnlyMany (ROX), чтобы несколько подов могли
    читать конфигурационные файлы, но никто не мог изменять их.
    - Если вы хотите использовать PV для хранения данных, которые должны быть доступны только
    одному поду, вы можете использовать режим ReadWriteOnce (RWO).
    - Если вы хотите использовать PV для хранения данных, которые должны быть доступны
    нескольким подам и могут быть изменены, вы можете использовать режим ReadWriteMany (RWX).

    - Retain: Этот режим сохраняет данные в PV даже после того, как PV будет удален.
    Данные будут сохранены на хост-машине, где PV был создан.
    - Delete: Этот режим удаляет данные в PV после того, как PV будет удален. Данные
    будут удалены с хост-машине, где PV был создан.
    - Recycle: Этот режим удаляет данные в PV и затем создает новый PV с теми же
    характеристиками. Этот режим не рекомендуется использовать, поскольку он может
    привести к потере данных.

    Эти persistentVolumeReclaimPolicy определяют, что произойдет с данными в PV после
    того, как PV будет удален.
    - Например, если вы хотите сохранить данные в PV даже после того, как PV
    будет удален, вы можете использовать режим Retain.
    - Если вы хотите удалить данные в PV после того, как PV будет удален, вы можете
    использовать режим Delete.
    - Если вы хотите удалить данные в PV и затем создать новый PV с теми же
    характеристиками, вы можете использовать режим Recycle.

```

## Advanced-3

```txt
1 - Что такое Service Mesh?


->  Service Mesh - это архитектурный подход к управлению микросервисами в
    распределенной системе. Он представляет собой слой инфраструктуры, который
    обеспечивает управление и мониторинг взаимодействия между микросервисами.

    Service Mesh обеспечивает следующие функции:
    - Управление трафиком: Service Mesh позволяет управлять потоком трафика между
    микросервисами, включая маршрутизацию, балансировку нагрузки и ограничение скорости.
    - Мониторинг и трассировка: Service Mesh позволяет мониторить и трассировать
    взаимодействие между микросервисами, включая сбор метрик и логов.
    - Безопасность: Service Mesh обеспечивает безопасность взаимодействия между
    микросервисами, включая шифрование и аутентификацию.
    - Управление конфигурацией: Service Mesh позволяет управлять конфигурацией
    микросервисов, включая управление версиями и конфигурацией окружения.

    Service Mesh состоит из следующих компонентов:
    - Sidecar: Sidecar - это контейнер, который запускается вместе с микросервисом
    и обеспечивает управление и мониторинг взаимодействия между микросервисами.
    - Service Mesh обычно реализуется путем предоставления каждому экземпляру
    сервиса экземпляра прокси, который называется Sidecar. Sidecar обрабатывают коммуникации
    между сервисами, производят мониторинг и устраняют проблемы безопасности, то есть все,
    что может быть абстрагировано от отдельных сервисов.
    - Control Plane: Control Plane - это компонент, который управляет Sidecar и
    обеспечивает управление и мониторинг взаимодействия между микросервисами.
    - Data Plane: Data Plane - это компонент, который обеспечивает передачу данных
    между микросервисами.

    Service Mesh имеет следующие преимущества:
    - Улучшение управления: Service Mesh обеспечивает улучшенное управление
    взаимодействием между микросервисами.
    - Улучшение безопасности: Service Mesh обеспечивает улучшенную безопасность
    взаимодействия между микросервисами.
    - Улучшение мониторинга: Service Mesh обеспечивает улучшенный мониторинг
    взаимодействия между микросервисами.

    Service Mesh имеет следующие недостатки:
    - Сложность: Service Mesh может быть сложным для установки и управления.
    - Дополнительная нагрузка: Service Mesh может добавить дополнительную нагрузку на систему.

    Примеры Service Mesh:
    - Istio от Google, IBM и Lyft, на данный момент является самый известной Service
    Mesh-архитектурой. А Kubernetes, который изначально разрабатывался в Google,
    сейчас является единственным фреймворком для оркестрации контейнеров, который
    поддерживается Istio.
    - Linkerd: Linkerd - это Service Mesh, который обеспечивает управление и мониторинг
    взаимодействия между микросервисами.
    - Consul: Consul - это Service Mesh, который обеспечивает управление и мониторинг
    взаимодействия между микросервисами.
```

```txt
2 - Какие типы секретов есть в kubernetes?

->  Opaque Secret: Этот тип секрета используется для хранения конфиденциальных данных,
    таких как пароли, ключи и сертификаты. Opaque Secret хранит данные в виде
    base64-кодированного строки.

    kubernetes.io/dockerconfigjson Secret: Этот тип секрета используется для хранения
    конфигурации Docker Registry. Этот тип секрета хранит данные в виде JSON-объекта.

    Также есть еще один тип секрета, который называется kubernetes.io/service-account-token
    Secret, но он используется только для сервис-аккаунтов и не может быть создан вручную.

    apiVersion: v1
    kind: Secret
    metadata:
        name: my-secret
    type: Opaque
    data:
        username: <base64 encoded username>
        password: <base64 encoded password>
```

```txt
3 - Как обеспечить отказоустойчивость кластера kubernetes?

->  - Распределение узлов: Распределите узлы кластера по нескольким физическим
    серверам или виртуальным машинам, чтобы обеспечить высокую доступность. 
    (Создание узлов/Конфигурация узлов)
    - Использование контроллера: Используйте контроллер для управления узлами и
    обеспечения отказоустойчивости.
    - Использование реплик: Используйте реплики для обеспечения отказоустойчивости приложений.
    - Использование сервисов: Используйте сервисы для обеспечения доступа к приложениям и
    обеспечения отказоустойчивости.
    - Использование Persistent Volume: Используйте Persistent Volume для обеспечения
    сохранения данных приложений.
    - Использование Backup и Restore: Используйте Backup и Restore для обеспечения
    сохранения данных приложений и восстановления их в случае отказа.
    - Использование мониторинга и логирования: Используйте мониторинга и логирования
    для обеспечения контроля над работой кластера и выявления проблем.
    - Использование автоматического масштабирования: Используйте автоматическое
    масштабирование для обеспечения масштабирования кластера в зависимости от нагрузки.
```

```txt
4 - Как можно разграничить доступ к нейспейсам/объектам внутри кластера?

->  - Role-Based Access Control (RBAC): RBAC - это механизм управления доступом,
    который позволяет назначать роли пользователям или группам, определяя их права
    доступа к ресурсам кластера.
    - Service Accounts: Service Accounts - это специальные учетные записи, которые
    используются для аутентификации и авторизации сервисов внутри кластера.
    - Network Policies: Network Policies - это механизм управления доступом к сетям,
    который позволяет определять правила доступа к ресурсам кластера.
    - Namespace-Based Access Control: Namespace-Based Access Control - это механизм
    управления доступом, который позволяет определять права доступа к ресурсам кластера
    на основе нейспейсов.

    RBAC
     - RBAC - это механизм управления доступом, который позволяет назначать роли
     пользователям или группам, определяя их права доступа к ресурсам кластера.
     - Роли: Роли - это набор прав доступа, которые определяют, что пользователь или
     группа могут делать с ресурсами кластера.
     - Ролебиндинги: Ролебиндинги - это связь между ролью и пользователем или группой,
     которая определяет права доступа пользователя или группы к ресурсам кластера.

    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
        name: my-role
    rules:
    - apiGroups: ["*"]
      resources: ["*"]
      verbs: ["*"]
---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
        name: my-rolebinding
    roleRef:
        name: my-role
        kind: Role
    subjects:
    - kind: User
      name: my-user
      namespace: my-namespace

    Service Accounts
     - Service Accounts - это специальные учетные записи, которые используются для
     аутентификации и авторизации сервисов внутри кластера.
     - Service Account: Service Account - это учетная запись, которая используется для
     аутентификации и авторизации сервисов внутри кластера.
     - Service Account Token: Service Account Token - это токен, который используется
     для аутентификации и авторизации сервисов внутри кластера.

    Network Policies
     - Network Policies - это механизм управления доступом к сетям, который позволяет
     определять правила доступа к ресурсам кластера.
     - Network Policy: Network Policy - это набор правил, которые определяют доступ к
     ресурсам кластера.
     - Network Policy Ingress: Network Policy Ingress - это набор правил, которые определяют
     доступ к ресурсам кластера извне кластера.

    Namespace-Based Access Control
     - Namespace-Based Access Control - это механизм управления доступом, который позволяет
     определять права доступа к ресурсам кластера на основе нейспейсов.
     - Namespace: Namespace - это логический раздел кластера, который содержит ресурсы
     кластера.
     - Namespace-Based Access Control: Namespace-Based Access Control - это механизм
     управления доступом, который позволяет определять права доступа к ресурсам кластера
     на основе нейспейсов.
```

## <a id="kubectl">kubectl</a>

```txt
1 - Подключение к кластеру.
2 - Основные команды.
```

### Notice-4

```txt
1 - Как подключиться к кластеру с помощью kubectl?

->  Чтобы подключиться к кластеру с помощью kubectl, необходимо указать контекст, в котором 
    находится кластер. Это можно сделать двумя способами

    1-kubectl config use-context <имя-контекста>
    2-kubectl --context=<имя-контекста> <команда>
    3-kubectl --kubeconfig=/path/to/config get pods
    4-kubectl config set-cluster <имя-кластера> --server=<адрес-сервера> 
      --insecure-skip-tls-verify
    5-kubectl config set-credentials <имя-пользователя> --token=<токен>
    6-kubectl config set-context my-context --cluster=my-cluster --user=my-user
    7-export KUBECONFIG=/path/to/config
```

```txt
2 - Как вывести список подов в неймпейсе по умолчанию?

->  kubectl get pods -n default -o wide/json, смотря какой у нас ns по умолчанию
```

```txt
    3 - Как установить неймспейс по умолчанию?

->  kubectl config set-default-namespace <имя-неймспейса>
    kubectl config set-default-namespace --all <имя-неймспейса>
    kubectl config set-default-namespace --cluster=<имя-кластера> <имя-неймспейса>
    kubectl config set-context --current --namespace=<имя-неймспейса>
    kubectl config set-context <имя-контекста> --namespace=<имя-неймспейса>
    kubectl config view
    kubectl config set --namespace=<имя-неймспейса>
    export KUBE_NAMESPACE=<имя-неймспейса>
    ~/.kube/config
        apiVersion: v1
        kind: Config
        preferences:
            namespace: my-namespace
```

```txt
4 - Что такое kubectl profile?

->  kubectl profile - это функция в kubectl, которая позволяет создавать и
    управлять несколькими профилями конфигурации. Профиль конфигурации - это
    набор настроек, которые определяют, как kubectl взаимодействует с кластером Kubernetes.

    Профиль конфигурации может включать в себя следующие элементы:
        - Контекст: определяет, какой кластер Kubernetes использовать.
        - Неймспейс: определяет, какой неймспейс использовать по умолчанию.
        - Пользователь: определяет, какой пользователь использовать для аутентификации.
        - Сервер: определяет, какой сервер Kubernetes использовать.
        - Токен: определяет, какой токен использовать для аутентификации.
    Профили конфигурации можно использовать для различных целей, таких как:
        - Разделение доступа к разным кластерам Kubernetes.
        - Управление доступом к разным неймспейсам.
        - Управление доступом к разным пользователям.
        - Управление конфигурацией для разных окружений (например, разработка,
        тестирование, производство).

    kubectl profile позволяет создавать, редактировать и удалять профили конфигурации

    kubectl config create-profile dev --context=my-dev-cluster 
    --namespace=my-dev-namespace --user=my-dev-user
    -----------------------------------------------------------
    kubectl config create-profile test --context=my-test-cluster
    --namespace=my-test-namespace --user=my-test-user
    -----------------------------------------------------------
    kubectl config use-profile dev
    kubectl config use-profile test
```

### Intern-4

```txt
1 - Какие есть форматы вывода?

->  kubectl поддерживает несколько форматов вывода, которые можно использовать
    для вывода информации о ресурсах Kubernetes

    1-wide: Этот формат вывода показывает дополнительную информацию о ресурсах,
            такую как IP-адреса, порты и т. д.
            kubectl get pods -o wide
    2-yaml: Этот формат вывода показывает информацию о ресурсах в формате YAML.
            kubectl get pods -o yaml
    3-json: Этот формат вывода показывает информацию о ресурсах в формате JSON.
            kubectl get pods -o json
    4-jsonpath: Этот формат вывода позволяет вывести информацию о ресурсах в
            формате JSON, используя выражения JSONPath.
            kubectl get pods -o jsonpath='{.items[0].metadata.name}'
    5-name: Этот формат вывода показывает только имена ресурсов.
            kubectl get pods -o name
    6-annotations: Этот формат вывода показывает аннотации ресурсов.
            kubectl get pods -o annotations
    7-labels: Этот формат вывода показывает метки ресурсов.
            kubectl get pods -o labels
```

```txt
2 - Как вывести детальное описание объекта в консоль с помощью kubectl?

->  kubectl describe pods/nodes/deploy/svc/ingress/ns/pv/sts/pvc
    Например, можно использовать опцию -f для вывода информации в формате YAML или JSON
        kubectl describe pod <имя-пода> -f yaml
    Также можно использовать опцию -l для вывода информации о ресурсах,
    которые соответствуют определенным меткам.
        kubectl describe pod -l app=<имя-приложения>
```

```txt
3 - Как отредактировать объект с помощью kubectl?

->  kubectl edit pods/nodes/deploy/svc/ingress/ns/pv/sts/pvc
    Также можно использовать команду kubectl patch для редактирования
    объектов. Эта команда позволяет редактировать объекты, используя JSON-патч.
        kubectl patch deployment <имя-деплоймента> -p '{"spec":{"replicas":3}}'
    Например, можно использовать опцию -f для редактирования файла в формате YAML или JSON.
        kubectl patch deployment <имя-деплоймента> -f yaml -p '{"spec":{"replicas":3}}'

    1-kubectl apply -f <имя-файла> --prune
    2-kubectl patch <имя-объекта> -p '{"spec":{"replicas":3}}'
    3-kubectl edit <имя-объекта> -o yaml
    4-kubectl replace -f <имя-файла>
    5-kubectl annotate <имя-объекта> <имя-аннотации>=<значение-аннотации>
    6-kubectl label <имя-объекта> <имя-метки>=<значение-метки>
```

### Advanced-4

```txt
1 - Как с помощью kubectl вывести поды с определённым значением лейбла? 

->  Чтобы вывести поды с определённым значением лейбла с помощью kubectl,
    можно использовать команду
    kubectl get pods -l app=my-app
    kubectl get pods -l app!=my-app
    kubectl get pods -l app=my-app -l env=
    kubectl get pods -l app in (my-app,my-app2)
    kubectl get pods -l app notin (my-app,my-app2)
```
